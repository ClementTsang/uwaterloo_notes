\documentclass{article}

\usepackage{times}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{fullpage}
\usepackage{color}
\usepackage{courier}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{hyperref}
\graphicspath{{./}}

\lstset{language=c, keywordstyle={\bfseries \color{red}}, basicstyle=\footnotesize\ttfamily}
\setlength{\paperheight}{11in}
\author{Clement Tsang}

\begin{document}

\begin{center}
    \Large{CS 458 --- Module 3}
\end{center}

\section{Outline}
\begin{itemize}
    \item Allows different entities to access different resources in a shared manner.
    \item The OS needs to control this sharing and provide an interface for allowing this access.
    \item Identification and authentication are required for access control.
    \item Focus on memory protection for now.
\end{itemize}

\section{Protection in General Purpose Operating Systems}
\subsection{History}
\begin{itemize}
    \item Worth looking at how OSes have evolved until now.
    \item They now allow multiple users to use the same hardware, and added sequential abilities to run multiple \emph{executives}.  
    \item The OS should make resources available to users if required and permitted to by some policy.
    \item OSes also protect users from each other; attacks, mistakes, malware, and resource overconsumption are things to protect against, even if it is a single-user OS.
\end{itemize}
\subsection{Protection Basics}
\begin{itemize}
    \item Some protected objects:
        \begin{itemize}
            \item Memory
            \item Data
            \item CPU
            \item Programs
            \item I/O devices
            \item Networks
            \item The OS itself
        \end{itemize}
\end{itemize}

\subsection{Memory Protection}
\begin{itemize}
    \item We talk about memory protection first --- a program should not be able to read the memory of another program unless permitted.
    \item This is important as a \emph{lot} of things are stored in memory!
    \item One way to invoke security is separation --- keep a user's objects separate from another's!
    \item We can do this:
        \begin{itemize}
            \item Physically (easy but expensive and inefficient)
            \item Temporally (execute different users' programs at different times)
            \item Logically (users don't see other users)
            \item Cryptographically (make users unable to see other user's data unencrypted)
        \end{itemize}
    \item But sometimes, users do want to share resources.
    \item For example, library routines or files/DB records.
    \item OSes should allow for flexible sharing --- but this creates new questions:
        \begin{itemize}
            \item Which files to share?  What part?
            \item Which users?
            \item Which users can share objects further?
            \item What uses are permitted?  R/W/E perms?  Maybe only specific bits of information (ie: only aggregate info, not individual entries of a DB).
            \item How long?
        \end{itemize}
    \item Often, for memory protection, the OS can exploit hardware support (virtual memory from CS 350) for a cheap solution.
    \item Memory addresses used are virtual and the MMU will manage this and translate to physical addresses.
    \item the OS maintains the mapping tables the MMU will use and deals with raised exceptions from the MMU.
    \item What kinds of hardware support is used for memory protection?
    \item The simplest is a fence register --- exception if the memory access below addresses is in the fence register.
    \begin{itemize}
        \item This protects the OS from user programs.
        \item This only works for a single-user OS.
    \end{itemize}
    \item Another technique is base/bound register pairs.
        \begin{itemize}
            \item This throws an exception if memory access is below/above an address in the base/bound register.
            \item Each user program has different values.
            \item When a ctx switch occurs, the OS is responsible for moving the current base/bond registers to the currently executing user program.
            \item We can extend this to have 2 base-bound pairs, one for code, one for data.
            \item This approach is more flexible.
        \end{itemize}
    \item The tagged architecture takes this to the extreme; each memory word has one or more extra bits that identify access rights to the word.
        \begin{itemize}
            \item This is very flexible, but it incurs a large overhead and is not portable at all.
        \end{itemize}
    \item Segmentation is a common approach (remember CS 350?).
        \begin{itemize}
            \item Each program has multiple address spaces, or segments.
            \item We have different segments for code, data, stack, though this can be split up even further.
            \item The virtual address contains of two parts --- the segment name, and the offset within the segment.
            \item The OS will keeps mappings from the segment name to its base physical address in the segment table; one is made for each process.
            \item The OS can relocate/resize segments and share them between processes.
            \item The segment table can also keep protection attributes.
            \item However, because of the resizing/relocation capabilities, this means every access requires a bounds check.
        \end{itemize}
    \item In paging, we divide the virtual and physical address spaces into pages and frames respectively.  Frame size is equal to page size.
        \begin{itemize}
            \item The virtual address consists of the page number and offset within page.
            \item The number of bits for the offset is $\log_2($page size$)$.
            \item The OS keeps the mapping from page number to its base physical address in the page table.
            \item Similarly to segmentation, protection attributes are kept in the page table.
            \item Typically used; advantages are:
                \begin{itemize}
                    \item Each address reference is checked for protection by hardware
                    \item Prevent users from accessing unpermitted pages
                    \item Less used pages can be moved to disk
                    \item Users can share access to a page
                \end{itemize}
            \item Disadvantages:
                \begin{itemize}
                    \item Internal fragmentation still is a problem
                    \item Assigning different levels of protection of different classes of data items is not feasible
                \end{itemize}
        \end{itemize}
    \item The x86 architecture supports both segmentation and paging, though paging is more common.
    \item Memory protection bits can indicate no access, R/W access, or RO access.
    \item Processors now also typically include a no execute bit, or NX bit.  This forbids execution of instructions stored in a page, which would make the stack/heap non-executable.
    \item Note that this does not stop buffer overflow attacks; see module 2 (see return oriented programming, where we don't inject new code but change existing code to do what we want).
\end{itemize}

\subsection{Access Control}
\begin{itemize}
    \item Access control has 3 goals:
        \begin{enumerate}
            \item Check every access
            \item Enforce the least privilege
            \item Verify acceptable use
        \end{enumerate}
    \item To describe the access control matrix, we first define some sets:
        \begin{itemize}
            \item Set of protected objects: $O$
            \item Set of protected subjects: $S$
            \item Set of rights: $R$
        \end{itemize}
        The access control matrix consists of entries $a[s, o]$, where $s \in S$, $o \in O$, and $a[s, o] \subseteq R$.
    \item For example, we could make a table like:
        \begin{table}[h]
        \centering
        \begin{tabular}{|l|l|l|l|}
        \hline
              & File 1 & File 2 & File 3 \\ \hline
        Alice & orw    & rx     & o      \\ \hline
        Bob   & r      & orx    &        \\ \hline
        Carol &        &        &        \\ \hline
        \end{tabular}
        \end{table}
    \item Often, access control matrices are not actually implemented as a matrix\dots the size and time would be awful to deal with.
    \item It's too sparse!
    \item Instead, typically they use access control lists, a set of capabilities, or some combination.
    \item An access control list, or ACL, is such that each object has a list of subjects and their access rights.
    \item We can quickly determine sets of allowed users per object, or revoking access to one specific object, but determining which objects a user can access or revoking a user's access to all objects is slow.
    \item For example, digital signatures.
    \item We can make tokens transferable.
    \item An example of combining usage of ACLs and capabilities:
        \begin{itemize}
            \item In Unix, each file has an ACL, which is consulted when executing an \lstinline{open()} call.
            \item If approved, then the caller is given a capability listing type of access allowed in ACL.
            \item Upon \lstinline{read()} or \lstinline{write()} call, the OS looks at capability to determine whether type of access is allowed.
            \item This doesn't completely mediate; it does not check \emph{every} access.
        \end{itemize}
    \item Another way to do access control is role-based access control, or RBAC.
    \item Administrators assign users to roles and grant access rights to roles.
    \item This is similar to groups but groups are less flexible.  A group is a set of subjects, while a role is as set of privileges to objects.
    \item When a user takes over a new role, they need to update only their role assignment, not all their access rights.
    \item Many commercial DBs do this.
    \item Also supports more complex access control scenarios:
        \begin{itemize}
            \item Hierarchical roles --- a manager is also an employee; this reduces the number of role/access rights assignments
            \item Users can have multiple roles and assume/give up roles as required
            \item Separation of duty --- maybe a task needs two people of different roles that cannot be the same person
        \end{itemize}
\end{itemize}

\section{User Authentication}
\begin{itemize}
    \item Computers often have to identify and authenticate users before authorizing them.
    \item Difficult for computers to do for people both locally and remotely.
    \item Four classes of authentication factors:
        \begin{itemize}
            \item Something the user knows
            \item Something the user has
            \item Something the user is (biometrics)
            \item Something about the user's context (location, time, devices in proximity, etc.)
        \end{itemize}
    \item Authentication factors may be combined for multi-factor authentication (ie: 2FA).
    \item Using multiple factors from the same class may not be a good idea; for example 2 passwords isn't really useful.
    \item Also, must make sure the factor cannot be changed --- for example, a factor the user has can become a factor the user knows, like tokens that can be easily duplicated (mag strips) or SMS messages (ie: SIM-jacking).
\end{itemize}

\subsection{Passwords}
\begin{itemize}
    \item A familiar and old authentication method.
    \item Enter an ID and password, potentially multiple attempts are allowed.
    \item Many usability problems:
        \begin{itemize}
            \item Entering passwords may be inconvenient.
            \item Password composition/change rules.
            \item Forgotten passwords may not be recoverable; people tend to forget them.
            \item If a password is shared then updating passwords is difficult.
        \end{itemize}
    \item And security problems:
        \begin{itemize}
            \item If the password is leaked, then an individual can immediately access the protected resource unless something like 2FA is used.
            \item Shoulder surfing.
            \item Keylogging.
            \item Interface illusions/phishing.
            \item Password re-use.
            \item Password guessing (brute-forcing, for example).
        \end{itemize}
    \item Some guessing attacks are exhaustive searching, dictionary attacks, etc.
    \item In online attacks, we can try to stop this by rate-limiting.  This can still be defeated by social engineering mechanisms, though.  For example, bypassing via secret questions/recovery methods.
    \item Password hygiene can be helped by things like password managers (though this now keeps all eggs in one basket), or passphrases that are easier to remember but still hard to guess.
    \item Don't reveal your passwords, don't use passwords on public computers, and don't re-use passwords.
    \item Advice for developers:
        \begin{itemize}
            \item Don't use password composition rules.
            \item At least 8 characters minimum length.
            \item At least 64 characters max length.
            \item Allow any characters.
            \item Blacklist frequently used/compromised passwords.
            \item Avoid password hints or secret questions.
            \item Don't force users to change passwords.
            \item Allow passwords to be copy-pasted.
            \item Use 2FA (but avoid SMS-based).
        \end{itemize}
    \item Attacks on password files --- websites need to store passwords (or something) in a file to validate password inputs.
    \item Passwords in plaintext is a stupid idea as access to it from an intruder or\dots anyone really, could immediately screw over a lot of people.
    \item Cryptographic tools:
        \begin{itemize}
            \item Hash --- compute a fixed-length, one-way output.  Deterministic.
            \item MAC --- takes a secret key as an input value; otherwise a hash.  Deterministic.
        \end{itemize}
    \item Now, store a hash of the password in the password file.
    \item Compare the \emph{hash of the input} with the stored hash (fingerprint).
    \item But this would still allow offline guessing attacks\dots
    \item Add a user-specific \emph{salt} to the password fingerprint.
    \item So two users with the same password have different fingerprints.
    \item This makes pre-computed tables useless.
    \item Using an iterated hash function which is slow to compute is better than using a standard hash function that would be fast to compute.
    \item This would not be noticed when a user inputs a password, but much more noticeable during a brute-force attack.
    \item Then, to make it better, throw in a MAC instead of a cryptographic hash.
    \item This adds a secret key required to compute the password fingerprint.
    \item This makes guessing attacks based on the fingerprints alone useless, but would require some kind of secret key generation/storage, using software/hardware.
    \item If the key does leak, then the scheme remains as secure as a scheme based on solely a cryptographic hash.
    \item How do we do password recovery?
    \item Well, that would require storing the password in some way\dots that's a no-go.
    \item So, use password-resetting mechanisms instead!
    \item Interception attacks --- intercept the password as it is being sent to the server.
    \item OTP (one-time passwords) make this attack useless; for example fobs, auth. apps, challenge-response protocols.
    \item A challenge-response protocol is using a random challenge to the client and the completion of the client + password computes a one-time password.
    \item Also, passwords (or their hashes) are usually encrypted via TLS to protect from interception attacks.
    \item Though sometimes, they're still transmitted via PT!
    \item There are also cryptographic protocols, like SRP, that make intercepted info useless to an attacker.
    \item Unlock patterns are an alternative.
    \item May have an issue; fingerprints/smudges may reveal the combination!
    \item Another graphical password is image selection; this has some issues with randomness and shoulder-surfing.
    \item Systems should authenticate the user, but the user should also authenticate the server is real!
    \item Biometrics are hailed as a way to get rid of problems with password and token-based authentication.
    \item Problems:
        \begin{itemize}
            \item Observed fingerprint just has to be \emph{close enough}, otherwise it would be too hard to use reliably.
            \item Could potentially be tricked if not done correctly (ie: face identification).
            \item Not secret!
            \item Cannot change!
        \end{itemize}
    \item Authentication vs. identification --- former is checking whether a captured trait corresponds to a particular stored trait, while the latter is if it corresponds to \emph{any of the stored traits}.
    \item False positives can make biometrics-based identification useless (ie: Alice is accepted as Bob).
    \item Another potential example of the base rate fallacy --- if the base rate is low and there are some false positives, it will seem like a huge failure.
    \item More issues with biometrics: privacy, accuracy.
\end{itemize}

\section{Security policies and models}
\begin{itemize}
    \item Trusting something means that if that entity misbehaves, the security of the system fails.
    \item We trust an OS if we have confidence it provides security services (memory/file production, access control and user auth.).
    \item Typically a trusted OS will build on four factors:
        \begin{enumerate}
            \item Policy (a set of rules outlining what is secured and why)
            \item Model (a model that implements the policy and that can be used for reasoning about the policy)
            \item Design (a spec. of how the OS implements the model)
            \item Trust (assurance that the OS is implemented according to design)
        \end{enumerate}
    \item We expect trusted software to do what it says it is going to do, and nothing more.
    \item We also expect:
        \begin{itemize}
            \item Functional correctness --- does it work correctly?
            \item Enforcement of integrity --- wrong input won't impact the correctness of data (test via fuzzing).
            \item Limited privilege --- access rights are minimized and not passed to others if not intended.
            \item Appropriate confidence level --- software has been rated as required by the environment.
        \end{itemize}
    \item Trust can change over time.
\end{itemize}

\subsection{Security Policies}
\begin{itemize}
    \item Security policies had their roots in military security policies.
    \item Each object/subject had a sensitivity/clearance level --- for example, ``Top Secret'' $>_c$ ``Secret'' $>_c$ ``Confidential'' $>_c$ ``Unclassified''.
    \item Each object/subject might also be assigned to one or more compartments; this means that people would know only what they needed to know.
    \item A subject $s$ could only access object $o$ iff their level was greater than that of the object, and their allowed compartments were a superset (or equal) of the compartments that $o$ used.
    \item If $s$ dominates $o$, then we could denote it as $s \geq_{dom} o$.
    \item So if someone had clearance ``Top Secret'' and access to compartment ``East Germany'', then they could not access a document that had the same clearance but a compartment of ``East Germany'' \emph{and} ``Soviet Union''!
    \item The integrity of information could be more important than confidentiality --- Clark-Wilson Security Policy.
    \item Uses transactions; remember DBs!
    \item Another issue is potential conflicts of interests --- Chinese Wall Security Policy; hard to go to the other side of the wall once you're on one side.
    \item Once you have been given access to some specific information, you cannot access information of other categories in a similar manner, for example.
    \item Think of being able to access info about a company, and being restricted from accessing similar data from competing companies, or the like.
    \item The \emph{ss-property} means that subject $s$ can access object $o$ iff each object previously accessed by $s$ either belongs to the same company as $o$ or a different kind of company than $o$.
    \item The \emph{*-property} means that for a write access to $o$ from $s$, we also need to ensure that all objects readable by $s$ either belong to the same company as $o$ or have been sanitized.
        \begin{itemize}
            \item The *-property prevents writing such that there is indirect information flow.
        \end{itemize}
    \item Many security models have been defined with may properties; however their relevance to practically used security models may not be clear.
    \item We focus on looking at two prominent models:
        \begin{itemize}
            \item Bell-La Padula Confidentiality
            \item Biba Integrity
        \end{itemize}
    \item These are targeted at multilevel security (MLS) policies, where subjects/objects have clearance/classification levels.
\end{itemize}

\subsection{Lattices}
\begin{itemize}
    \item The dominance relationship $\geq_{dom}$ is transitive and anti-symmetric.
    \item It defines a partial order (you cannot have $a \geq b$ and $b \geq a$) (subscript omitted for brevity).
    \item In a \emph{lattice}, for every $a$ and $b$, there is a unique lowest upper bound $u$ for which $u \geq a$ and $u \geq b$ and a unique greatest lower bound $l$ for $a \geq l$ and $b \geq l$.
    \item There are also two elements $U$ and $L$ that dominate/are dominated by all levels.
\end{itemize}

\subsection{BLP}
\begin{itemize}
    \item Regulates information flow in MLS policies, like lattice-based ones.
    \item Users should get info only according to their clearance!
    \item The underlying principle is information can only flow up.
    \item The ss-property is ``no read up'' --- $s$ should have read access to $o$ only if $C(s) \geq C(o)$.
    \item The *-property is ``no write down'' --- $s$ should have write access to $o$ only if $C(o) \geq C(s)$.
    \item Typically though, strict enforcement is too restrictive.
\end{itemize}

\subsection{Biba}
\begin{itemize}
    \item To prevent inappropriate modification of data.
    \item Subjects/objects are ordered by an integrity classification scheme, $l(s)$ and $l(o)$.
    \item Write access: $s$ can only modify $o$ if $l(s) \geq l(o)$ (unreliable person cannot modify file with high integrity info).
    \item Read access: $s$ can read $o$ only if $l(o) \geq l(s)$ (unreliable information cannot contaminate subject).
    \item In practice, Biba's rules are \emph{too} restrictive, as a subject can never read a lower integrity object.
    \item We can instead use a dynamic integrity level.
    \item The \emph{Subject Low Watermark Property} is where if $s$ reads $o$ then $l(s) = min(l(s, l(o)))$.
    \item The \emph{Object Low Watermark Property} is where if $s$ modifies $o$, then $l(o) = min(l(s), l(o))$.
    \item The integrity of subject/object can only go down --- that is, info flows down.
\end{itemize}

\subsection{Review of BLP and Biba}
\begin{itemize}
    \item Very simple which makes proving properties about them easy.
    \item For example, we can prove that if a system starts secure, it remains secure.
    \item But they are \emph{too} simple.
    \item For example, we need declassification, we need confidentiality \emph{and} integrity, we need object creation.
    \item And information leaks can still be possible through covert channels!
    \item So what do?
\end{itemize}

\subsection{Information Flow Control}
\begin{itemize}
    \item Describes authorized paths along which information can flow.
    \item For example, BLP describes a lattice-based information flow policy.
    \item For a compiler-based information flow control, a compiler would check whether the information flow in a program would violate the policy.
    \item How could information flow from a variable to another?
    \item It could be explicit (\lstinline{y = x;}) or implicit (\lstinline{if (x = 1) y = 0; else y = 1;}).
    \item The input parameters of a program could have a lattice-based security classification associated with them.
    \item The compiler would then go through the program and update the security classification of each variable depending on the individual statements that update the variable.
    \item Therefore, a security classification for each variable that is output by the program are computed.
    \item A user/program is allowed to see the output only if allowed by its security classification!
\end{itemize}

\section{Trusted OS Design}
\begin{itemize}
    \item Eight design principles for security:
        \begin{itemize}
            \item Least privilege: give the least privileges possible
            \item Economy of mechanism: use simple and straightforward protection mechanisms
            \item Open design: avoid security by obscurity (Kerckhoff's principle/Shannon's maxim)
            \item Complete mediation: every access attempt must be checked
            \item Permission based/fail-safe defaults: default should be denial of access
            \item Separation of privileges: avoid a single point of failure; perhaps use two or more conditions to get access (ie: 2fa, dual-custody)
            \item Least common mechanism: avoid one failure in a mechanism from cascading; don't share mechanisms if possible
            \item Ease of use: if the protection mechanism is difficult to use, people will not want to use it correctly or at all
        \end{itemize}
    \item Some security features of a trusted OS:
        \begin{itemize}
            \item Access control:
                \begin{itemize}
                    \item Mandatory access control (central authority establishes permissions).
                    \item Discretionary access control (owners of an object have some control over who can access what).
                \end{itemize}
            \item Object reuse protection
                \begin{itemize}
                    \item Suppose memory is used to store a password.
                    \item If someone else uses the same memory, the OS should have erased that memory so that other users can't peek into the memory to find old, sensitive data.
                    \item This is also the case for data.  For example, a hidden file, or data within a file, may actually still exist despite being deleted/hidden.
                \end{itemize}
            \item Trusted path
                \begin{itemize}
                    \item Give assurance to a user that their inputs are being sent to the correct receiver application.
                    \item This is difficult.
                \end{itemize}
            \item Accountability and auditing
                \begin{itemize}
                    \item Keep an audit log of security-related events.
                    \item This provides accountability if something goes wrong.
                    \item Something something Murphy.
                    \item The audit log does not give accountability though if an attacker can \emph{modify} said log.
                    \item The granularity of event logging may be important --- if it is too fine-grained then finding an attack or storing it may  become a problem.  But if it is too coarse, then we might miss the attack entirely!
                \end{itemize}
            \item Intrusion detection
                \begin{itemize}
                    \item Alarm if behaviour looks suspicious.
                \end{itemize}
        \end{itemize}
\end{itemize}

\subsection{Trusted Computing Base (TCB)}
\begin{itemize}
    \item The TCB consists of the part of a trusted OS that is necessary to enforce OS security policy.
    \item The security kernel runs below the operating system level; this makes it harder to attack.
    \item In the ring structure, it is between OS and hardware.
    \item It should be minimal and only have core functionality.
    \item Many OSes don't use the 4 rings of an x86 architecture (Linux and Windows only use user and supervisor mode).
    \item The reference monitor is a collection of access controls for devices, files, memory, etc.
        \begin{itemize}
            \item Important part of TCB.
            \item Must be tamperproof, un-bypassable, and analyzable.
        \end{itemize}
\end{itemize}

\subsection{Virtualization}
\begin{itemize}
    \item A way to provide logical separation/isolation.
    \item Virtual memory, for example, uses a page mapping to give processes the impression of having separate memory spaces.
    \item We can go further with virtual \emph{machines}.  These virtualize, well, a machine, with virtual I/O devices, files, etc.
    \item This means that attacks would be limited to the virtual environment.
\end{itemize}

\subsection{Application Insulation}
\begin{itemize}
    \item A similar approach; shield applications from other apps.
    \item The application is partitioned into trusted and untrusted code.
    \item The former is encrypted in memory with the key in secure hardware, while the latter talks to trusted code via an API.
    \item Examples are Intel SGX and AMD memory encryption.
\end{itemize}

\subsection{Security in Popular OSes}
\begin{itemize}
    \item Windows has UAC for temporary access rights, and integrity levels.
    \item In UNIX, root has full access to anything.
    \item SELinux/AppArmor provide MAC to Linux.
    \item Other approaches like Chroot, compartmentalization, SUID also exist for UNIX.
    \item And smartphones usually restrict apps in terms of what they can access.
    \item \lstinline{chroot} sandboxes/jails a command by changing its root directory.
        \begin{itemize}
            \item Thus, the process cannot access files outside of the jail.
            \item This is not perfect though, there are ways to break out of it and some commands/programs get difficult to use in a jail.
        \end{itemize}
    \item Containers can run processes in a set of namespaces (process IDs, user IDs, filesystem mounts, etc.), which means that the process cannot see many things from the client machine.  Examples are Docker.
        \begin{itemize}
            \item This also means that a program can get elevated privileges \emph{only} within the container, and not the actual client machine.
        \end{itemize}
    \item Compartmentalization splits applications into parts and apply the least privilege on each part.
        \begin{itemize}
            \item For example, OpenSSH splits SSH into a privileged monitor and a jailed, unprivileged child.
            \item The child must contact the monitor to get protected information.
            \item The child will be shut down by the monitor if it finds the child suspicious.
        \end{itemize}
    \item setuid/suid bit
        \begin{itemize}
            \item UNIX ACLs contain a suid bit.
            \item If it is set, then the executable will run under the identity of its owner, \emph{not} the caller.
            \item So, \lstinline{passwd} belongs to root and has suid bit set.
            \item This means the program will run as root.
            \item There is a possibility of a ``confused deputy'' attack, where an attacker can fool the program into thinking they are another user which could potentially cause some harm (ie: passwd changing password for another user than the one calling it).
        \end{itemize}
\end{itemize}

\subsection{Assurance}
\begin{itemize}
    \item How to convince people to trust our software?
    \item Testing and formal verification are two aforementioned ways.
    \item Validation is another.
    \item These are things that a trusted entity can evaluate for software, certifying that it satisfies some criteria.
    \item Two well-known setso f criteria are the Orange Book (US) and the Common Criteria.
    \item The OB lists several ratings based on evaluation and security.
    \item Ranges from D to A1.
    \item For example, Windows NT has C2, UNIXes are usually C1.
    \item The international version of this is the Common Criteria.  Products are rated against profiles, where there is EAL 1 (worst) to EAL 7 (best).
    \item RHEL and Windows 7 have EAL 4+, for example.
\end{itemize}

\end{document}
